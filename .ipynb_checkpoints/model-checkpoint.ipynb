{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# import libraries here\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Activation, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "print('All libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "# downloading data\n",
    "\n",
    "def download(url, file):\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "        #Unzip the downloaded file to get pickled data\n",
    "        zip = ZipFile('data.zip')\n",
    "        zip.extractall()\n",
    "\n",
    "# Downloading the training and test dataset.\n",
    "download('https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip', 'data.zip')\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesurement file read successful\n"
     ]
    }
   ],
   "source": [
    "# reading measurement file\n",
    "\n",
    "lines = []\n",
    "\n",
    "with open('./data/driving_log.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "print('mesurement file read successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data reading completed.\n"
     ]
    }
   ],
   "source": [
    "# reading images and measurements from measurement file\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "    # reading center image\n",
    "    source_path = line[0]\n",
    "    file_name = source_path.split('/')[-1]\n",
    "    current_path = './data/IMG/' + file_name\n",
    "    image = cv2.imread(current_path)\n",
    "    measurement = float(line[3])\n",
    "    images.append(image)\n",
    "    measurements.append(measurement)\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "print('data reading completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_9 (Lambda)                (None, 160, 320, 3)   0           lambda_input_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_9 (Cropping2D)        (None, 65, 320, 3)    0           lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_46 (Convolution2D) (None, 31, 158, 24)   1824        cropping2d_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_47 (Convolution2D) (None, 14, 77, 36)    21636       convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_48 (Convolution2D) (None, 5, 37, 48)     43248       convolution2d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_49 (Convolution2D) (None, 3, 35, 64)     27712       convolution2d_48[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_50 (Convolution2D) (None, 1, 33, 80)     46160       convolution2d_49[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 2640)          0           convolution2d_50[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 100)           264100      flatten_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 100)           0           dense_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 50)            5050        activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 50)            0           dense_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 10)            510         activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 10)            0           dense_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 1)             11          activation_27[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 410,251\n",
      "Trainable params: 410,251\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generating model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Pre-processing data\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "\n",
    "# Layer 1: convolution layer, input 65 x 320 x 3, output 63 x 318 x 32\n",
    "#model.add(Convolution2D(24, 5, 5, subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2,2), activation=\"relu\"))\n",
    "\n",
    "model.add(Convolution2D(24, 5, 5, activation=\"relu\"))\n",
    "\n",
    "# Layer 2: convolution layer\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2,2), activation=\"relu\"))\n",
    "\n",
    "# Layer 3: convolution layer\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2,2), activation=\"relu\"))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation=\"relu\"))\n",
    "model.add(Convolution2D(80, 3, 3, activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 2/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 3/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 4/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0085 - val_loss: 0.0103\n",
      "Epoch 8/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 9/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 10/10\n",
      "6428/6428 [==============================] - 16s - loss: 0.0075 - val_loss: 0.0105\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=10)\n",
    "\n",
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
